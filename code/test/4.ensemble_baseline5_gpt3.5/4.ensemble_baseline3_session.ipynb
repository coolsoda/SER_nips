{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "# use your openai key\n",
    "key = 'sk-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session in the data\n",
      "['Ses01F', 'Ses01M', 'Ses02F', 'Ses02M', 'Ses03F', 'Ses03M', 'Ses04F', 'Ses04M', 'Ses05F', 'Ses05M']\n",
      "-------------\n",
      "a sample entry:\n",
      "need_prediction: no\n",
      "emotion: fru\n",
      "id: Ses01F_script01_1_F000\n",
      "speaker: Ses01_F\n",
      "groundtruth: What's he going to say?\n",
      "hubertlarge: what's he ging to say\n",
      "w2v2100: what's he gen to say\n",
      "w2v2960: what's he going to say\n",
      "w2v2960large: what's he going to say\n",
      "w2v2960largeself: what's he going to say\n",
      "wavlmplus: whats he gon to say\n",
      "whisperbase: What's he gonna say?\n",
      "whisperlarge: What's he gonna say?\n",
      "whispermedium: What's he gonna say?\n",
      "whispersmall: What's he gonna say?\n",
      "whispertiny: What's he gonna say?\n",
      "ensemble: What's he going to say?\n"
     ]
    }
   ],
   "source": [
    "file_path = 'F:\\\\SLT_2024\\\\train_ensemble\\\\combined\\\\combined.json'\n",
    "\n",
    "# Open the JSON file and load its contents into a Python dictionary\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "session_dict = {}\n",
    "\n",
    "for item in data:\n",
    "    session_id = item['id'][:6]\n",
    "    if session_id not in session_dict:\n",
    "        session_dict[session_id] = []\n",
    "    session_dict[session_id].append(item)\n",
    "\n",
    "# list the session in the training data\n",
    "print('session in the data')\n",
    "print(list(session_dict.keys()))\n",
    "\n",
    "# print a sample entry of the first session\n",
    "first_session = session_dict[list(session_dict.keys())[0]]\n",
    "\n",
    "# Print each key-value pair in the first dictionary\n",
    "print('-------------\\na sample entry:')\n",
    "for key, value in first_session[0].items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key='sk-')\n",
    "log = []\n",
    "\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(10))\n",
    "def gpt_request(**kwargs):\n",
    "  return client.chat.completions.create(**kwargs)\n",
    "\n",
    "# predict the emotion of a sentence considerating the conversation context, using gpt-3.5-turbo based on whisper-tiny transcription\n",
    "def gpt_emotion_predictor(context, cur_input, number_of_contexts=3):\n",
    "  \"\"\"\n",
    "  Predicts the emotional state of a speaker based on the current input sentence and the conversational context.\n",
    "\n",
    "  Parameters:\n",
    "  context (list of dict): A list of dictionaries, each representing a previous conversational turn. Each dictionary\n",
    "                          should contain at least the keys 'speaker' and 'sentence' indicating who the speaker was\n",
    "                          and what they said, respectively.\n",
    "  cur_input (dict): A dictionary representing the current sentence to be analyzed. It should contain at least the keys\n",
    "                    'speaker' and 'sentence', similar to the dictionaries in `context`.\n",
    "  number_of_contexts (int, optional): The number of contextual entries to consider for emotion prediction. Defaults to 3. The more context, the more expensive.\n",
    "\n",
    "  Returns:\n",
    "  str: The predicted emotion for the current sentence, from a set of predefined emotions such as 'happy', 'sad',\n",
    "        'neutral', or 'angry'.\n",
    "  \"\"\"\n",
    "\n",
    "  emotion_code_dict = {'happy': 'hap', 'neutral': 'neu', 'angry': 'ang', 'sad': 'sad'}\n",
    "  # for simplicity, we just use whisper-tiny's transcription, feel free to use any transcription we provide, and you can combine them\n",
    "  background = 'Two speakers are talking. The conversation is:\\n'\n",
    "  context = '\\n'.join(f\"{item['speaker']}: {item['ensemble']}\" for item in context[-number_of_contexts:]) + '\\n'\n",
    "  cur_sentence = f\"Now speaker {cur_input['speaker']} says: '{cur_input['ensemble']}'. \\n\"\n",
    "  task = f\"Predict the emotion of the sentence '{cur_input['ensemble']}' from the options [happy, sad, neutral, angry], consider the conversation context, do not explain, only output the label in [happy, sad, neutral, angry].\"\n",
    "  prompt = background + context + cur_sentence + task\n",
    "  #print(prompt)\n",
    "  chat_history = [{\"role\": \"system\", \"content\": \"You are a speech emotion predictor.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}]\n",
    "  response = gpt_request(\n",
    "             model=\"gpt-3.5-turbo\",\n",
    "             messages=chat_history).choices[0].message.content.strip().lower()\n",
    "  #print('Predicted emotion:', response)\n",
    "  #print('----------')\n",
    "  if response not in emotion_code_dict:\n",
    "    # model may still output emotion that is not in our list, project to neutral\n",
    "    # print('prediction not in the options ', response)\n",
    "    pred_emotion = 'neu'\n",
    "  else:\n",
    "    pred_emotion = emotion_code_dict[response]\n",
    "  log.append([prompt, response])\n",
    "  return pred_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session Ses01F\n",
      "# ground truth emotion 259 # predicted emotion 259\n",
      "session Ses01M\n",
      "# ground truth emotion 295 # predicted emotion 295\n",
      "session Ses02F\n",
      "# ground truth emotion 254 # predicted emotion 254\n",
      "session Ses02M\n",
      "# ground truth emotion 239 # predicted emotion 239\n",
      "session Ses03F\n",
      "# ground truth emotion 273 # predicted emotion 273\n",
      "session Ses03M\n",
      "# ground truth emotion 250 # predicted emotion 250\n",
      "session Ses04F\n",
      "# ground truth emotion 240 # predicted emotion 240\n",
      "session Ses04M\n",
      "# ground truth emotion 257 # predicted emotion 257\n",
      "session Ses05F\n",
      "# ground truth emotion 241 # predicted emotion 241\n",
      "session Ses05M\n",
      "# ground truth emotion 269 # predicted emotion 269\n"
     ]
    }
   ],
   "source": [
    "# input an entire session (conversation), and return a sequence of predictions of each sentence (that requires a prediction)\n",
    "def predict_session(session):\n",
    "  num_sentence = len(session)\n",
    "  # a sequence of ground truth and predicted emotions, only record sentences that need prediction (i.e., emotion falls in [hap, sad, neu, ang])\n",
    "  emotion_ground_truth, emotion_prediction = [], []\n",
    "  for i, cur_sentence in enumerate(session):\n",
    "    need_pred = cur_sentence['need_prediction']\n",
    "    # if an emotion prediction is required for this sentence\n",
    "    if need_pred == 'yes':\n",
    "      cur_label = cur_sentence['emotion']\n",
    "      # context is all previous sentences in the conversation\n",
    "      cur_context = session[0:i]\n",
    "      # input both context and the current sentence to the emotion predictor\n",
    "      try:\n",
    "        # avoid send request too frequent\n",
    "        time.sleep(0.1)\n",
    "        cur_pred = gpt_emotion_predictor(cur_context, cur_sentence)\n",
    "        emotion_ground_truth.append(cur_label)\n",
    "        emotion_prediction.append(cur_pred)\n",
    "      except:\n",
    "        # if there is an error, fill a neutral to keep the output of same dimension\n",
    "        print('openai api has an error.')\n",
    "        emotion_ground_truth.append('neu')\n",
    "        emotion_prediction.append('neu')\n",
    "    # # sanity check with few samples\n",
    "    # if i > 5:\n",
    "    #   break\n",
    "  return emotion_ground_truth, emotion_prediction\n",
    "\n",
    "# predict for all sessions\n",
    "all_ground_truth, all_pred = [], []\n",
    "for session in session_dict:\n",
    "  # predictions of each session\n",
    "  print('session', session)\n",
    "  emotion_ground_truth, emotion_prediction = predict_session(session_dict[session])\n",
    "  print('# ground truth emotion', len(emotion_ground_truth), '# predicted emotion', len(emotion_prediction))\n",
    "  # concatenae predictions of all sessions\n",
    "  all_ground_truth += emotion_ground_truth\n",
    "  all_pred += emotion_prediction\n",
    "\n",
    "csv.writer(open('F:\\\\SLT_2024\\\\train4\\\\pred.csv', 'w', newline='')).writerow(all_pred)\n",
    "csv.writer(open('F:\\\\SLT_2024\\\\train4\\\\truth.csv', 'w', newline='')).writerow(all_ground_truth)\n",
    "json.dump(log, open('F:\\\\SLT_2024\\\\train4\\\\log.json', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "def evaluate_emotions(emotion_ground_truth, emotion_prediction):\n",
    "    \"\"\"\n",
    "    Calculates the unweighted accuracy and plots the confusion matrix for given lists of ground truth and predicted emotions.\n",
    "\n",
    "    Parameters:\n",
    "    emotion_ground_truth (list of str): The list of true emotion labels.\n",
    "    emotion_prediction (list of str): The list of predicted emotion labels.\n",
    "    \"\"\"\n",
    "    class_report = classification_report(emotion_ground_truth, emotion_prediction, labels=['neu', 'sad', 'hap', 'ang'])\n",
    "    print(\"Classification Report:\\n\", class_report)\n",
    "    # Calculate unweighted accuracy\n",
    "    accuracy = accuracy_score(emotion_ground_truth, emotion_prediction)\n",
    "    print(f\"Unweighted Accuracy: {accuracy}\")\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(emotion_ground_truth, emotion_prediction, labels=['neu', 'sad', 'hap', 'ang'])\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['neu', 'sad', 'hap', 'ang'], yticklabels=['neu', 'sad', 'hap', 'ang'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.show()\n",
    "\n",
    "evaluate_emotions(all_ground_truth, all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
